---
title: "Car price prediction Ridge regression"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load the dataset
```{r}
load("rda/carPrice.rda")
head(carPrice)
```

Create a matrix "x" of all independent variables and store dependent variable in "y".
```{r}
x <- model.matrix(price~.,data=carPrice)[,-1]
y <-carPrice$price
```

Divide you data in 70:30 
```{r}
set.seed(1)
train= sample(1:nrow(x), 0.7*nrow(x))
```

Store indices into test which is not present in train
```{r}
test = (-train)
```

Dependend variable for test data
```{r}
y.test = y[test]
```

library(glmnet)
```{r include=FALSE}
library(glmnet)
```

Cross Validation to find lambda values
```{r}
cv.out <- cv.glmnet(x[train,],y[train],alpha=0)
```

Plot crossvalidation output.
```{r}
plot(cv.out)
```

Optimal lamda 
```{r}
minlamda <- cv.out$lambda.min

minlamda
```

Apply model on train dataset at lambda equal to minlamda
```{r}
ridge.mod <- glmnet(x[train,],y[train],alpha=0,lambda =minlamda)
```

Prediction on test dataset
```{r}
ridge.pred <- predict(ridge.mod,s=minlamda,newx=x[test,])
```

MSE with ridge 
```{r}
mean((ridge.pred-y.test)^2)
```

Apply model on train dataset at lambda equal to zero, LR without regularisation
```{r}
ridge.mod <- glmnet(x[train,],y[train],alpha=0,lambda = 0)
```

Linear Regression model
```{r}
ridge.pred_0 <- predict(ridge.mod,s=0,newx=x[test,])
```

MSE Linear regression model
```{r}
mean((ridge.pred_0-y.test)^2)
```

Final model Coefficents 
```{r}
ridge_coef <-predict(ridge.mod,type="coefficients",s=minlamda)
ridge_coef
```